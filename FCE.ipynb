{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FCE.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1ZbV2fJffEQN",
        "igFL7phLwkrc"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZbV2fJffEQN"
      },
      "source": [
        "# Importando bibliotecas e arquivos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZFIHXA0PTjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd0a6eb6-bad9-4f33-d944-9338b8cce1c4"
      },
      "source": [
        "import random\n",
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn.metrics as metrics\n",
        "from plotly import graph_objects as go\n",
        "from google.colab import files\n",
        "from sklearn.covariance import EmpiricalCovariance, MinCovDet\n",
        "\n",
        "import warnings\n",
        "\n",
        "# Ignorando warnings de runtime da cov robusta\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "smpsinal =np.load('/content/drive/MyDrive/Filtro_casado_estocastico/Dados/SmpSinal.npy')\n",
        "smpruido =np.load('/content/drive/MyDrive/Filtro_casado_estocastico/Dados/SmpRuido.npy')\n",
        "EneStile=np.load('/content/drive/MyDrive/Filtro_casado_estocastico/Dados/TileModSinal.npy')\n",
        "EneRtile=np.load('/content/drive/MyDrive/Filtro_casado_estocastico/Dados/TileModRuido.npy')\n",
        "EneStmdb_ch=np.load('/content/drive/MyDrive/Filtro_casado_estocastico/Dados/TMDBSinalCh.npy')\n",
        "EneRtmdb_ch=np.load('/content/drive/MyDrive/Filtro_casado_estocastico/Dados/TMDBRuidoCh.npy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igFL7phLwkrc"
      },
      "source": [
        "# Definindo as funções"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "resIvk1vwugc"
      },
      "source": [
        "### Função para branqueamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MygcxPIJwo4s"
      },
      "source": [
        "def bran(c):\n",
        "  \"\"\"\n",
        "  Branqueamento\n",
        "  \"\"\"\n",
        "\n",
        "  D, V = np.linalg.eig(c)\n",
        "\n",
        "  # reordenando autovalores e autovetores pra ficar igual ao matlab\n",
        "  indices = np.argsort(D)\n",
        "  D = D[indices]\n",
        "  D = D.real\n",
        "  V = V[:, indices]\n",
        "\n",
        "  D = D**(-0.5) # esta é a primeira parte do calculo do W\n",
        "  D = D*np.identity(7) # agrupei o array D em uma matriz diagonal\n",
        "\n",
        "  W = np.matmul(D,V.T) # produto matricial\n",
        "\n",
        "  return W"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2cxBb9kw-31"
      },
      "source": [
        "### Função que calcula o pulso médio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0-xI4Xgw_NE"
      },
      "source": [
        "def mp(nf):\n",
        "  \"\"\"\n",
        "  Returns the medium pulse\n",
        "  \"\"\"\n",
        "  a0 = 0.0\n",
        "  a1 = 0.0\n",
        "  a2 = 0.0\n",
        "  a3 = 0.0\n",
        "  a4 = 0.0\n",
        "  a5 = 0.0\n",
        "  a6 = 0.0\n",
        "\n",
        "  for i in range(len(nf)):\n",
        "    a0 = a0 + nf[i][0]\n",
        "    a1 = a1 + nf[i][1]\n",
        "    a2 = a2 + nf[i][2]\n",
        "    a3 = a3 + nf[i][3]\n",
        "    a4 = a4 + nf[i][4]\n",
        "    a5 = a5 + nf[i][5]\n",
        "    a6 = a6 + nf[i][6]\n",
        "\n",
        "  a0 = a0/len(nf)\n",
        "  a1 = a1/len(nf)\n",
        "  a2 = a2/len(nf)\n",
        "  a3 = a3/len(nf)\n",
        "  a4 = a4/len(nf)\n",
        "  a5 = a5/len(nf)\n",
        "  a6 = a6/len(nf)\n",
        "\n",
        "  sm = []\n",
        "\n",
        "  sm.append(a0)\n",
        "  sm.append(a1)\n",
        "  sm.append(a2)\n",
        "  sm.append(a3)\n",
        "  sm.append(a4)\n",
        "  sm.append(a5)\n",
        "  sm.append(a6)\n",
        "\n",
        "  div = max(sm)\n",
        "  for i in range(7):\n",
        "    sm[i] = sm[i]/div\n",
        "  \n",
        "  return sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo87k6_1VFdz"
      },
      "source": [
        "### Função para cov robusta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7wUCDG_VIdC"
      },
      "source": [
        "def robust_cov(A):\n",
        "  \"\"\"\n",
        "  retorna a covariância robusta\n",
        "  \"\"\"\n",
        "\n",
        "  robust_cov = MinCovDet().fit(A.T).covariance_\n",
        "\n",
        "  return robust_cov\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv5EEoolxPET"
      },
      "source": [
        "### Função para PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbJAJKtdxRkU"
      },
      "source": [
        "def pca(A):\n",
        " \"\"\" performs principal components analysis \n",
        "     (PCA) on the n-by-p data matrix A\n",
        "     Rows of A correspond to observations, columns to variables. \n",
        "\n",
        " Returns :  \n",
        "  coeff :\n",
        "    is a p-by-p matrix, each column containing coefficients \n",
        "    for one principal component.\n",
        "  score : \n",
        "    the principal component scores; that is, the representation \n",
        "    of A in the principal component space. Rows of SCORE \n",
        "    correspond to observations, columns to components.\n",
        "  latent : \n",
        "    a vector containing the eigenvalues \n",
        "    of the covariance matrix of A.\n",
        " \"\"\"\n",
        " # computing eigenvalues and eigenvectors of covariance matrix\n",
        " M = (A-np.mean(A.T,axis=1)).T # subtract the mean (along columns)\n",
        " \n",
        " [latent,coeff] = np.linalg.eig(robust_cov(M)) # attention:not always sorted\n",
        "\n",
        " # reordenando autovalores e autovetores\n",
        " indices = np.argsort(latent)[::-1]\n",
        " latent = latent[indices]\n",
        " coeff = coeff[:, indices]\n",
        "\n",
        "\n",
        " score = np.dot(coeff.T,M) # projection of the data in the new space\n",
        " return coeff,score,latent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm0Iv1ABxmUd"
      },
      "source": [
        "### Função para aplicação do filtro"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV6vHU-_xrXc"
      },
      "source": [
        "def StochFilter(sinalTes, ruidoTes, ruidoDes, W, coeff, latent, mEstimacao):\n",
        "  \"\"\"\n",
        "  Filtering\n",
        "  \"\"\"\n",
        "\n",
        "  # Calculando os parametros\n",
        "\n",
        "  rRuido = np.matmul(ruidoTes, W.T)\n",
        "  rRuido = np.matmul(rRuido, coeff)\n",
        "\n",
        "  rSinal = np.matmul(sinalTes, W.T)\n",
        "  rSinal = np.matmul(rSinal, coeff)\n",
        "\n",
        "  variancia = np.var(ruidoDes)\n",
        "\n",
        "  No = variancia*2\n",
        "\n",
        "  N = 7\n",
        "\n",
        "  lbd = latent\n",
        "\n",
        "  h1 = np.zeros((7,7), dtype=float) \n",
        "  h2 = np.zeros((7,7), dtype=float) \n",
        "\n",
        "  aux1 = []\n",
        "  aux2 = []\n",
        "\n",
        "  for i in range(N):# de 1 ate o numero de pca\n",
        "      h1 = h1 + (lbd[i]/(lbd[i] + variancia)) * np.matmul(np.transpose(np.matrix(coeff[:][i])), np.matrix(coeff[:][i]))\n",
        "      h2 = h2 + (1/(lbd[i] + variancia)) * np.matmul(np.transpose(np.matrix(coeff[:][i])), np.matrix(coeff[:][i]))\n",
        "\n",
        "  # Componente Estocastica\n",
        "\n",
        "  IrRuido = np.zeros((len(ruidoTes),1), dtype=float) \n",
        "  IrSinal = np.zeros((len(ruidoTes),1), dtype=float) \n",
        "\n",
        "  for ev in range(len(ruidoTes)):\n",
        "    aux = np.transpose(np.matmul(rRuido[ev][:] , np.matrix(coeff[:][0:N])))\n",
        "    IrRuido[ev] = (1/No)*(np.matmul(np.matmul(rRuido[ev][:] , np.matrix(coeff[:][0:N])) , np.matmul(h1 , aux)))\n",
        "\n",
        "  for ev in range(len(sinalTes)):\n",
        "    aux = np.transpose(np.matmul(rSinal[ev][:] , np.matrix(coeff[:][0:N])))\n",
        "    IrSinal[ev] = (1/No)*(np.matmul(np.matmul(rSinal[ev][:] , np.matrix(coeff[:][0:N])) , np.matmul(h1 , aux)))\n",
        "\n",
        "  # Componente Deterministica\n",
        "\n",
        "  IdRuido = np.zeros((len(ruidoTes),1), dtype=float) \n",
        "  IdSinal = np.zeros((len(ruidoTes),1), dtype=float)\n",
        "\n",
        "  for ev in range(len(ruidoTes)):\n",
        "    aux = np.transpose(np.matmul(rRuido[ev][:] , np.matrix(coeff[:][0:N])))\n",
        "    IdRuido[ev] = np.matmul(np.matmul(mEstimacao , np.matrix(coeff[:][0:N])) , np.matmul(h2 , aux))\n",
        "\n",
        "  for ev in range(len(sinalTes)):\n",
        "    aux = np.transpose(np.matmul(rSinal[ev][:] , np.matrix(coeff[:][0:N])))\n",
        "    IdSinal[ev] = np.matmul(np.matmul(mEstimacao , np.matrix(coeff[:][0:N])) , np.matmul(h2 , aux))\n",
        "\n",
        "  FCestRuido = IdRuido + IrRuido\n",
        "  FCestSinal = IdSinal + IrSinal \n",
        "\n",
        "  # Etapa de estimaçaão de amplitude\n",
        "\n",
        "  b1 = np.matmul(np.matrix(coeff[:][0:N]) , np.matrix(np.transpose(coeff[:][0:N])))\n",
        "  b2 = (1/No) * np.matmul(np.matrix(coeff[:][0:N]) , np.matmul(np.matrix(h1) , np.transpose(np.matrix(coeff[:][0:N]))))\n",
        "  b3 = np.matmul(np.matmul(mEstimacao , np.transpose(np.matrix(coeff[:][0:N]))) ,  np.matmul(np.matrix(h2) , np.transpose(np.matrix(coeff[:][0:N]))))\n",
        "\n",
        "  ampRuido = np.zeros((len(ruidoTes),1), dtype=float) \n",
        "  ampSinal = np.zeros((len(ruidoTes),1), dtype=float)\n",
        "\n",
        "  a = (1/No) * np.matmul(np.matmul(mEstimacao , np.transpose(np.matrix(coeff[:][0:N]))),  np.matmul(np.matrix(h1) , np.transpose(np.matmul(mEstimacao , np.transpose(np.matrix(coeff[:][0:N]))))))\n",
        "  b = np.matmul(np.matmul(mEstimacao , np.transpose(np.matrix(coeff[:][0:N]))),  np.matmul(np.matrix(h2) , np.transpose(np.matmul(mEstimacao , np.transpose(np.matrix(coeff[:][0:N]))))))\n",
        "\n",
        "  cs=0;\n",
        "  cr=0;\n",
        "\n",
        "  for i in range(len(sinalTes)):\n",
        "    # ra = np.matmul(b , b) + 4 * np.matmul(a , FCestSinal[i][:]) \n",
        "    ra = b*b+4*a*FCestSinal[i]\n",
        "    if ra < 0:\n",
        "      ra = 0\n",
        "      cs = cs + 1\n",
        "    ampSinal[i] = (- b + np.sqrt(ra))/(2*a)\n",
        "  \n",
        "  for i in range(len(ruidoTes)):\n",
        "    # ra = np.matmul(b , b) + 4 * np.matmul(a , FCestRuido[i][:])\n",
        "    ra = b*b+4*a*FCestRuido[i]\n",
        "    if ra < 0:\n",
        "      ra = 0\n",
        "      cr = cr + 1\n",
        "    ampRuido[i] = (- b + np.sqrt(ra))/(2*a)\n",
        "\n",
        "\n",
        "  return FCestSinal, FCestRuido, ampSinal, ampRuido,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K54sBob6x24E"
      },
      "source": [
        "### Função pra curva ROC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbWcU5YXx60r"
      },
      "source": [
        "def roc(pontos, sinal, ruido):\n",
        "  \"\"\" calcula os parametros da curva ROC\n",
        "  (Receiver Operating Characteristic Curve)\n",
        "\n",
        " Retorna :  \n",
        "  FA :\n",
        "    falso alarme\n",
        "  PD :\n",
        "    probabilidade de detecção\n",
        "  \n",
        "  \"\"\"\n",
        "  pmin = min(ruido)\n",
        "  pmax = max(ruido)\n",
        "\n",
        "  psoma = (pmax+abs(pmin))/pontos\n",
        "  patamar = pmin\n",
        "  PD = []\n",
        "  FA = []\n",
        "  pd = 0\n",
        "  fa = 0\n",
        "\n",
        "  for i in range(pontos):\n",
        "    for j in range(len(ruido)):\n",
        "      if sinal[j] > patamar:\n",
        "        pd = pd + 1\n",
        "      if ruido[j] > patamar:\n",
        "        fa = fa + 1\n",
        "    \n",
        "    pd = pd*100/len(sinal)\n",
        "    fa = fa*100/len(ruido)\n",
        "    PD.append(pd)\n",
        "    FA.append(fa)\n",
        "    pd = 0\n",
        "    fa = 0\n",
        "    patamar = patamar + psoma\n",
        "\n",
        "  FA = np.array(FA)\n",
        "  PD = np.array(PD)\n",
        "\n",
        "  return FA, PD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7SFKaRcx_aM"
      },
      "source": [
        "### Função para ponto de PD = 98%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiDcBbinyBr8"
      },
      "source": [
        "def p98(FA, PD):\n",
        "  \"\"\"\n",
        "  retorna os valores do ponto (x,y) da curva mais proximo de 98%\n",
        "  \"\"\"\n",
        "\n",
        "  x = []\n",
        "  y = []\n",
        "\n",
        "  for i in range(len(PD)):\n",
        "    if PD[i]>=0.98:\n",
        "      y.append(PD[i])\n",
        "      x.append(FA[i])\n",
        "  x = min(x)\n",
        "  y = min(y)\n",
        "  return x, y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn5poK-FRcdL"
      },
      "source": [
        "# Testes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_1UQBCtRemi"
      },
      "source": [
        "# Selecionando o lado e módulo\n",
        "# side = 1\n",
        "# mod = 57\n",
        "EneSTMDB=EneStmdb_ch.sum(axis=2)\n",
        "EneRTMDB=EneRtmdb_ch.sum(axis=2)\n",
        "base_fpr = np.linspace(0, 1, 1000)\n",
        "\n",
        "size_kfold=10  #escolhendo o numero de kfold - normalmente de faz com 10 \n",
        "kf=KFold(n_splits=size_kfold,shuffle=False)\n",
        "\n",
        "data = [[],[],[],[],[],[],[],[],[],[]]\n",
        "\n",
        "# pontos = open(\"pontos.txt\",  'w+')\n",
        "\n",
        "for side in range(0,1):\n",
        "  for mod in range(0,1):\n",
        "    # Calculando o pedestal para cada canal\n",
        "\n",
        "    ped = np.array([0.0, 0.0, 0.0, 0.0]).astype(np.float)\n",
        "\n",
        "    for i in range(np.size(ped)):\n",
        "      for j in range(np.size(smpruido, 4)):\n",
        "        ped[i] = ped[i] + smpruido[side][mod][i][4][j]\n",
        "\n",
        "    for i in range(4):\n",
        "      ped[i] = ped[i]/np.size(smpruido, 4)\n",
        "\n",
        "    # Separando os dados por canal\n",
        "\n",
        "    ruido0 = []\n",
        "    ruido1 = []\n",
        "    ruido2 = []\n",
        "    ruido3 = []\n",
        "    for j in range(np.size(smpruido, 4)):\n",
        "      aux0 = []\n",
        "      aux1 = []\n",
        "      aux2 = []\n",
        "      aux3 = []\n",
        "      for i in range(np.size(smpruido, 3)):\n",
        "        aux0.append(smpruido[side][mod][0][i][j])\n",
        "        aux1.append(smpruido[side][mod][1][i][j])\n",
        "        aux2.append(smpruido[side][mod][2][i][j])\n",
        "        aux3.append(smpruido[side][mod][3][i][j])\n",
        "      ruido0.append(aux0)\n",
        "      ruido1.append(aux1)\n",
        "      ruido2.append(aux2)\n",
        "      ruido3.append(aux3)\n",
        "\n",
        "\n",
        "    sinal0 = []\n",
        "    sinal1 = []\n",
        "    sinal2 = []\n",
        "    sinal3 = []\n",
        "    for j in range(np.size(smpsinal, 4)):\n",
        "      aux0 = []\n",
        "      aux1 = []\n",
        "      aux2 = []\n",
        "      aux3 = []\n",
        "      for i in range(np.size(smpsinal, 3)):\n",
        "        aux0.append(smpsinal[side][mod][0][i][j])\n",
        "        aux1.append(smpsinal[side][mod][1][i][j])\n",
        "        aux2.append(smpsinal[side][mod][2][i][j])\n",
        "        aux3.append(smpsinal[side][mod][3][i][j])\n",
        "      sinal0.append(aux0)\n",
        "      sinal1.append(aux1)\n",
        "      sinal2.append(aux2)\n",
        "      sinal3.append(aux3)\n",
        "\n",
        "    # Separando o conjunto de dados para treino (80%) e para teste (20%)\n",
        "\n",
        "    ruido0 = np.array(ruido0)\n",
        "    ruido1 = np.array(ruido1)\n",
        "    ruido2 = np.array(ruido2)\n",
        "    ruido3 = np.array(ruido3)\n",
        "\n",
        "    sinal0 = np.array(sinal0)\n",
        "    sinal1 = np.array(sinal1)\n",
        "    sinal2 = np.array(sinal2)\n",
        "    sinal3 = np.array(sinal3)\n",
        "\n",
        "    ruido0 = ruido0 - ped[0]\n",
        "    ruido1 = ruido1 - ped[1]\n",
        "    ruido2 = ruido2 - ped[2]\n",
        "    ruido3 = ruido3 - ped[3]\n",
        "\n",
        "    sinal0 = sinal0 - ped[0]\n",
        "    sinal1 = sinal1 - ped[1]\n",
        "    sinal2 = sinal2 - ped[2]\n",
        "    sinal3 = sinal3 - ped[3]\n",
        "\n",
        "    ruidob=ruido1.T\n",
        "    ruido0pd=pd.DataFrame(ruido0.T)\n",
        "    sinal0pd=pd.DataFrame(sinal0.T) \n",
        "\n",
        "    ruido1pd=pd.DataFrame(ruido1.T)\n",
        "    sinal1pd=pd.DataFrame(sinal1.T) \n",
        "\n",
        "    ruido2pd=pd.DataFrame(ruido2.T)\n",
        "    sinal2pd=pd.DataFrame(sinal2.T) \n",
        "\n",
        "    ruido3pd=pd.DataFrame(ruido3.T)\n",
        "    sinal3pd=pd.DataFrame(sinal3.T) \n",
        "\n",
        "    flag=0\n",
        "    tprs = []\n",
        "    tprs_SS = []\n",
        "    for train_index, test_index in kf.split(ruidob[0]):\n",
        "      \n",
        "      print('Lado:',side, 'modulo:',mod, 'Numero kfold:', flag)\n",
        "      \n",
        "      ruidoDes0 = ruido0pd.iloc[:,train_index]\n",
        "      ruidoTes0 = ruido0pd.iloc[:,test_index]\n",
        "      sinalDes0 = sinal0pd.iloc[:,train_index]\n",
        "      sinalTes0 = sinal0pd.iloc[:,test_index]\n",
        "\n",
        "      ruidoDes1 = ruido1pd.iloc[:,train_index]\n",
        "      ruidoTes1 = ruido1pd.iloc[:,test_index]\n",
        "      sinalDes1 = sinal1pd.iloc[:,train_index]\n",
        "      sinalTes1 = sinal1pd.iloc[:,test_index]\n",
        "\n",
        "      ruidoDes2 = ruido2pd.iloc[:,train_index]\n",
        "      ruidoTes2 = ruido2pd.iloc[:,test_index]\n",
        "      sinalDes2 = sinal2pd.iloc[:,train_index]\n",
        "      sinalTes2 = sinal2pd.iloc[:,test_index]\n",
        "\n",
        "      ruidoDes3 = ruido3pd.iloc[:,train_index]\n",
        "      ruidoTes3 = ruido3pd.iloc[:,test_index]\n",
        "      sinalDes3 = sinal3pd.iloc[:,train_index]\n",
        "      sinalTes3 = sinal3pd.iloc[:,test_index]\n",
        "\n",
        "      zero1=np.zeros(len(test_index))\n",
        "      um1=np.ones(len(test_index))\n",
        "\n",
        "      true_value=np.concatenate((um1,zero1),axis=0)\n",
        "      \n",
        "\n",
        "      EneTMDB_S_test=pd.DataFrame(EneSTMDB[side][mod]).iloc[test_index]\n",
        "      EneTMDB_R_test=pd.DataFrame(EneRTMDB[side][mod]).iloc[test_index]\n",
        "\n",
        "      EneStile_test=pd.DataFrame(EneStile[side][mod]).iloc[test_index]\n",
        "      EneRtile_test=pd.DataFrame(EneRtile[side][mod]).iloc[test_index]\n",
        "\n",
        "      # Matriz de covariância do ruído antes do branqueamento\n",
        "\n",
        "      c0 = np.cov(ruidoDes0)\n",
        "      c1 = np.cov(ruidoDes1)\n",
        "      c2 = np.cov(ruidoDes2)\n",
        "      c3 = np.cov(ruidoDes3)\n",
        "\n",
        "      # Matriz de branqueamento\n",
        "\n",
        "      W0 = bran(c0)\n",
        "      W1 = bran(c1)\n",
        "      W2 = bran(c2)\n",
        "      W3 = bran(c3)\n",
        "\n",
        "      # Filtrando os dados para um corte de energia\n",
        "\n",
        "      F0 = []\n",
        "      F1 = []\n",
        "      F2 = []\n",
        "      F3 = []\n",
        "\n",
        "      # for i in range(len(sinalDes0.T)):\n",
        "\n",
        "        # if (EneStmdb_ch[side][mod][0][i] + EneStmdb_ch[side][mod][1][i] + EneStmdb_ch[side][mod][2][i] + EneStmdb_ch[side][mod][3][i])>3000:\n",
        "          \n",
        "        #   F.append(sinalDes.iloc[:,i])\n",
        "      A = 150#np.mean(EneStmdb_ch[side][mod][0][:])*4\n",
        "      B = 150#np.mean(EneStmdb_ch[side][mod][1][:])*4\n",
        "      C = 150#np.mean(EneStmdb_ch[side][mod][2][:])*2\n",
        "      D = 150#np.mean(EneStmdb_ch[side][mod][3][:])*2\n",
        "\n",
        "      sinalDes0 = np.array(sinalDes0.T)\n",
        "      sinalDes1 = np.array(sinalDes1.T)\n",
        "      sinalDes2 = np.array(sinalDes2.T)\n",
        "      sinalDes3 = np.array(sinalDes3.T)\n",
        "      \n",
        "      for i in range(len(sinalDes0)):\n",
        "        if (EneStmdb_ch[side][mod][0][i] > A):\n",
        "          if (np.max(sinalDes0[i][:]) < 200):\n",
        "            F0.append(sinalDes0[i][:])\n",
        "\n",
        "      for i in range(len(sinalDes1)):\n",
        "        if (EneStmdb_ch[side][mod][1][i] > B):\n",
        "          if (np.max(sinalDes1[i][:]) < 200):\n",
        "            F1.append(sinalDes1[i][:])\n",
        "\n",
        "      for i in range(len(sinalDes2)):\n",
        "        if (EneStmdb_ch[side][mod][2][i] > C):\n",
        "          if (np.max(sinalDes2[i][:]) < 200):\n",
        "            F2.append(sinalDes2[i][:])\n",
        "\n",
        "      for i in range(len(sinalDes3)):\n",
        "        if (EneStmdb_ch[side][mod][3][i] > D):\n",
        "          if (np.max(sinalDes3[i][:]) < 200):\n",
        "            F3.append(sinalDes3[i][:])\n",
        "            \n",
        "      # if len(F0) == 0:\n",
        "      #   F0 = np.zeros((len(sinalDes0.T),7))\n",
        "      \n",
        "      # if len(F1) == 0:\n",
        "      #   F1 = np.zeros((len(sinalDes0.T),7))\n",
        "      \n",
        "      # if len(F2) == 0:\n",
        "      #   F2 = np.zeros((len(sinalDes0.T),7))\n",
        "      \n",
        "      # L3 = len(F3)\n",
        "      # if len(F3) == 0:\n",
        "      #   F3 = np.zeros((len(sinalDes0.T),7))\n",
        "\n",
        "      NF0 = F0\n",
        "      NF1 = F1\n",
        "      NF2 = F2\n",
        "      NF3 = F3\n",
        "\n",
        "      for i in range(len(F0)):\n",
        "        div = max(F0[i])\n",
        "        for j in range(7):\n",
        "          NF0[i][j] = F0[i][j]/div\n",
        "\n",
        "      for i in range(len(F1)):\n",
        "        div = max(F1[i])\n",
        "        for j in range(7):\n",
        "          NF1[i][j] = F1[i][j]/div\n",
        "\n",
        "      for i in range(len(F2)):\n",
        "        div = max(F2[i])\n",
        "        for j in range(7):\n",
        "          NF2[i][j] = F2[i][j]/div\n",
        "\n",
        "      for i in range(len(F3)):\n",
        "        div = max(F3[i])\n",
        "        for j in range(7):\n",
        "          NF3[i][j] = F3[i][j]/div\n",
        "\n",
        "      # Obtendo o pulso médio dos dados normalizados e filtrados\n",
        "\n",
        "      sm0 = mp(NF0)\n",
        "      sm1 = mp(NF1)\n",
        "      sm2 = mp(NF2)\n",
        "      sm3 = mp(NF3)\n",
        "\n",
        "      NF0 = np.array(NF0)\n",
        "      NF1 = np.array(NF1)\n",
        "      NF2 = np.array(NF2)\n",
        "      NF3 = np.array(NF3)\n",
        "\n",
        "      # PCA e obtenção dos sinais médios\n",
        "\n",
        "      pca_data0 = np.matmul(NF0, W0.T)\n",
        "      coeff0, score0, latent0 = pca(pca_data0)\n",
        "\n",
        "      pca_data1 = np.matmul(NF1, W1.T)\n",
        "      coeff1, score1, latent1 = pca(pca_data1)\n",
        "\n",
        "      pca_data2 = np.matmul(NF2, W2.T)\n",
        "      coeff2, score2, latent2 = pca(pca_data2)\n",
        "\n",
        "      pca_data3 = np.matmul(NF3, W3.T)\n",
        "      coeff3, score3, latent3 = pca(pca_data3)\n",
        "\n",
        "      N = 7\n",
        "\n",
        "      mFC0 = np.matmul(sm0, W0.T)\n",
        "      mEstimacao0 = np.matmul(mFC0, coeff0)\n",
        "\n",
        "      mFC1 = np.matmul(sm1, W1.T)\n",
        "      mEstimacao1 = np.matmul(mFC1, coeff1)\n",
        "\n",
        "      mFC2 = np.matmul(sm2, W2.T)\n",
        "      mEstimacao2 = np.matmul(mFC2, coeff2)\n",
        "\n",
        "      mFC3 = np.matmul(sm3, W3.T)\n",
        "      mEstimacao3 = np.matmul(mFC3, coeff3)\n",
        "\n",
        "      # Cálculo das componentes do filtro\n",
        "      \n",
        "      sinalTes0 = np.array(sinalTes0.T)\n",
        "      ruidoTes0 = np.array(ruidoTes0.T)\n",
        "      ruidoDes0 = np.array(ruidoDes0.T)\n",
        "\n",
        "      sinalTes1 = np.array(sinalTes1.T)\n",
        "      ruidoTes1 = np.array(ruidoTes1.T)\n",
        "      ruidoDes1 = np.array(ruidoDes1.T)\n",
        "\n",
        "      sinalTes2 = np.array(sinalTes2.T)\n",
        "      ruidoTes2 = np.array(ruidoTes2.T)\n",
        "      ruidoDes2 = np.array(ruidoDes2.T)\n",
        "\n",
        "      sinalTes3 = np.array(sinalTes3.T)\n",
        "      ruidoTes3 = np.array(ruidoTes3.T)\n",
        "      ruidoDes3 = np.array(ruidoDes3.T)\n",
        "\n",
        "      FCestSinal0, FCestRuido0, ampSinal0, ampRuido0 = StochFilter(sinalTes0, ruidoTes0, ruidoDes0, W0, coeff0, latent0, mEstimacao0)\n",
        "      FCestSinal1, FCestRuido1, ampSinal1, ampRuido1 = StochFilter(sinalTes1, ruidoTes1, ruidoDes1, W1, coeff1, latent1, mEstimacao1)\n",
        "      FCestSinal2, FCestRuido2, ampSinal2, ampRuido2 = StochFilter(sinalTes2, ruidoTes2, ruidoDes2, W2, coeff2, latent2, mEstimacao2)\n",
        "      FCestSinal3, FCestRuido3, ampSinal3, ampRuido3 = StochFilter(sinalTes3, ruidoTes3, ruidoDes3, W3, coeff3, latent3, mEstimacao3)\n",
        "\n",
        "      FCestSinal = np.array(ampSinal0) + np.array(ampSinal1) + np.array(ampSinal2) + np.array(ampSinal3)\n",
        "      FCestRuido = np.array(ampRuido0) + np.array(ampRuido1) + np.array(ampRuido2) + np.array(ampRuido3)\n",
        "      \n",
        "  \n",
        "\n",
        "      saida_filtro=np.concatenate((FCestSinal,FCestRuido),axis=0)\n",
        "      \n",
        "      saida_TMDB=np.concatenate((EneTMDB_S_test,EneTMDB_R_test),axis=0)\n",
        "\n",
        "      saida_Tile=np.concatenate((EneRtile_test,EneStile_test),axis=0)\n",
        "\n",
        "      data[flag] = [[saida_filtro], [saida_Tile]] \n",
        "      \n",
        "      fpr, tpr, _ =metrics.roc_curve(true_value,saida_filtro)\n",
        "      tpr = np.interp(base_fpr, fpr, tpr)\n",
        "      tpr[0] = 0.0\n",
        "      tprs.append(tpr)\n",
        "\n",
        "      fpr_SS, tpr_SS, _ =metrics.roc_curve(true_value,saida_TMDB)\n",
        "      tpr_SS = np.interp(base_fpr, fpr_SS, tpr_SS)\n",
        "      tpr_SS[0] = 0.0\n",
        "      tprs_SS.append(tpr_SS)\n",
        "\n",
        "      flag += 1\n",
        "\n",
        "\n",
        "    tprs2 = np.array(tprs)\n",
        "    mean_tprs2 = tprs2.mean(axis=0)\n",
        "    std_tprs2 = tprs2.std(axis=0)\n",
        "    tprs_upper = np.minimum(mean_tprs2 + std_tprs2, 1)\n",
        "    tprs_lower = mean_tprs2 - std_tprs2\n",
        "    mean_auc = metrics.auc(base_fpr, mean_tprs2)\n",
        "\n",
        "    xFCE, yFCE = p98(base_fpr, mean_tprs2)\n",
        "\n",
        "\n",
        "    plt.plot(base_fpr, mean_tprs2, 'b', label ='Filtro Casado Estocastico(AUC = %0.4f)' %(mean_auc))\n",
        "    plt.fill_between(base_fpr, tprs_lower, tprs_upper, color='blue', alpha=0.3,label ='$\\pm$ 1. std. dev, (p = %0.3f, %0.3f)'  %(xFCE,yFCE))\n",
        "\n",
        "    tprs_SS2 = np.array(tprs_SS)\n",
        "    mean_SS = tprs_SS2.mean(axis=0)\n",
        "    std_SS= tprs_SS2.std(axis=0) \n",
        "    SS_upper = np.minimum(mean_SS + std_SS, 1)\n",
        "    SS_lower = mean_SS - std_SS\n",
        "\n",
        "    mean_ac_SS = metrics.auc(base_fpr, mean_SS)\n",
        "\n",
        "    xFC, yFC = p98(base_fpr, mean_SS)\n",
        "\n",
        "    plt.plot(base_fpr, mean_SS, 'r', label ='Aproximacao filtro casado (AUC = %0.4f)' %(mean_ac_SS))\n",
        "    plt.fill_between(base_fpr, SS_lower, SS_upper, color='red', alpha=0.3,label ='$\\pm$ 1. std. dev, (p = %0.3f, %0.3f)'  %(xFC,yFC))\n",
        "\n",
        "    p1=np.where(mean_tprs2<0.97)\n",
        "    p1 = p1[0][-1]+1\n",
        "    p2=np.where(mean_tprs2<0.998)\n",
        "    p2 = p2[0][-1]+1\n",
        "    plt.xlim([base_fpr[p1], base_fpr[p2]])\n",
        "    plt.ylim([mean_tprs2[p1], mean_tprs2[p2]])\n",
        "    #plt.xlim([0, 0.05])\n",
        "    # plt.ylim([0.95, 1])\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.ylabel('Taxa de Probabilidade de Detecção')\n",
        "    plt.xlabel('Taxa de falso alarme')\n",
        "    plt.title('Lado %d Modulo %d' %(side,mod))\n",
        "\n",
        "    # data = [base_fpr, mean_tprs2, tprs_lower, tprs_upper, mean_auc, mean_SS, SS_lower, SS_upper, mean_ac_SS]\n",
        "    filename = ('/content/drive/MyDrive/Filtro_casado_estocastico/Resultado_ROC_Canal/ROC_Parameters_side%d_mod%d.npy' %(side,mod))\n",
        "    np.save(filename,data)\n",
        "\n",
        "    plt.savefig('/content/drive/MyDrive/Filtro_casado_estocastico/Resultado_ROC_Canal/ROC_Side%d_mod%d.pdf' %(side,mod))\n",
        "    plt.clf()\n",
        "\n",
        "#     xFCE, yFCE = p98(base_fpr, mean_tprs2)\n",
        "#     xFC, yFC = p98(base_fpr, mean_SS)\n",
        "\n",
        "#     ar = [mean_auc, mean_ac_SS, xFCE, yFCE, xFC, yFC]\n",
        "\n",
        "#     for ele in ar:\n",
        "#       pontos.write(str(ele) + ',')\n",
        "#     pontos.write('\\n')\n",
        "\n",
        "\n",
        "\n",
        "# pontos.close()\n",
        "# files.download('pontos.txt') \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CQEgAXE3Bai"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}